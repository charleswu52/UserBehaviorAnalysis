# 基于Flink的电商用户行为分析

##  1 项目介绍

### 1.1 用户行为分类

- 统计分析
  – 点击、浏览
  – 热门商品、近期热门商品、分类热门商品,流量统计
- 偏好统计
  – 收藏、喜欢、评分、打标签
  – 用户画像（用户信息标签化）,推荐列表(结合特征工程和机器学习算法)
- 风险控制
  – 下订单、支付、登录
  – 刷单监控,订单失效监控,恶意登录(短时间内频繁登录失败)监控

偏好统计在这不做主要实现，涉及到机器学习算法相关的知识，因此本系统只设计实现统计分析与风险控制这两大模块。

### 1.2 项目模块设计

- 实时统计分析
  • 实时热门商品统计
  • 实时热门页面流量统计
  • 实时访问流量统计
  • APP 市场推广统计
  • 页面广告点击量统计
- 业务流程及风险控制
  • 页面广告黑名单过滤
  • 恶意登录监控
  • 订单支付失效监控
  • 支付实时对账

### 1.3 数据源解析

#### 用户行为数据

使用网上搜集的淘宝网某一天随机一百万用户的所有行为（包括点击、购买、 收藏 、喜欢 ）。数据集特征如下：

| 字段       | 数据类型 | 说明                             |
| ---------- | -------- | -------------------------------- |
| userId     | Long     | 用户ID                           |
| itemID     | Long     | 商品ID                           |
| categoryID | Integer  | 商品类别ID                       |
| behavior   | String   | 用户行为('pv','buy','cart','fav) |
| timestamp  | Long     | 行为发生的时间戳，单位秒         |

数据举例：

```
543462,1715,1464116,pv,1511658000
662867,2244074,1575622,pv,1511658000
561558,3611281,965809,pv,1511658000
894923,3076029,1879194,pv,1511658000
834377,4541270,3738615,pv,1511658000
```

#### web服务器日志

服务器端收集的用户访问日志，数据集特征如下：

| 字段      | 数据类型 | 说明                          |
| --------- | -------- | ----------------------------- |
| ip        | String   | 访问者IP                      |
| userID    | Long     | 访问者ID                      |
| eventTime | Long     | 访问时间                      |
| method    | String   | 访问方法(GET/POST/PUT/DELETE) |
| url       | String   | 访问的URL                     |

数据举例：

```
83.149.9.216 - - 17/05/2015:10:05:03 +0000 GET /presentations/logstash-monitorama-2013/images/kibana-search.png
83.149.9.216 - - 17/05/2015:10:05:43 +0000 GET /presentations/logstash-monitorama-2013/images/kibana-dashboard3.png
83.149.9.216 - - 17/05/2015:10:05:47 +0000 GET /presentations/logstash-monitorama-2013/plugin/highlight/highlight.js
83.149.9.216 - - 17/05/2015:10:05:12 +0000 GET /presentations/logstash-monitorama-2013/plugin/zoom-js/zoom.js
83.149.9.216 - - 17/05/2015:10:05:07 +0000 GET /presentations/logstash-monitorama-2013/plugin/notes/notes.js
```

## 2 实时热门商品统计

### 2.1 业务需求

统计近1小时内的热门商品,每5分钟更新一次，输出topN 的商品ID。

### 2.2 解决思路

1. 抽取出业务时间戳，告诉 Flink 框架基于业务时间做窗口
2. 过滤出浏览点击(“pv”)行为进行统计
3. 按一小时的窗口大小，每 5 分钟统计一次，做滑动窗口聚合（Sliding Window）
4. 按每个窗口聚合，输出每个窗口中点击量前 N 名的商品

## 3 实时流量统计

### 3.1 基于服务器 log 的热门页面浏览量统计

#### 3.1.1 业务需求

读取服务器日志中的每一行 log 统计在一段时间内用户访问 每一个 url 的次数 ，然后排序输出显示 。

#### 3.1.2 解决思路

与实现热门商品统计的思路相同，开一个10分钟的滑动窗口，每隔5秒滑动一次，输出最近 10 分钟内访问 量最多的前 N 个 URL。

### 3.2  网站总浏览量（ PV）的统计

#### 3.2.1 业务需求

实现统计一个网站在一个小时内总浏览量（PV，Page View）。

#### 3.2.2 解决思路

按照'pv'对用户行为进行过滤，然后开一个小时的滚动窗口，统计一个小时内的数量。

### 3.3 网站 独立访客数（UV）的统计

#### 3.3.1 业务需求

在一段时间内到底有多少不同的用户访问了网站。即存在一个统计指标是网站的独立访客数（Unique Visitor UV ）。 UV指的是一段时间（比如一小时）内访问网站的总人数， 1 天内同一访客的多次访问只记录为一个访客。

#### 3.3.2 解决思路

根据用户行为数据中的userId来区分不同的用户，有两种的实现思路：

1）第一种跟之前统计PV思路类似，在窗口函数中计算不同userId 的集合数量作为uv数量。

2）第二种使用使用布隆过滤器（ Bloom Filter ）对用户状态进行压缩。

第一种思路是把所有数据的userId 都存在了窗口计算的状态里，在窗口收集数据的过程中，状态会不断增大。但是在数据量很大的情况下，内存估计会爆掉而且性能下降，可以想到的一个思路是将数据存到Redis中进行缓存，但是如果数据量很大的时候可能需要扩展Redis集群，这样做明显代价太大。

因此更好的思路上从过滤出的数据上进行压缩，使用布隆过滤器（ Bloom Filter ）。不需要完整地存储用户ID 的信息，只要知道他在不在就行了。因此用一位（ bit ）就可以表示一个用户的状态。

本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure ），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存
在或者可能存在”。它本身是一个很长的二进制向量，既然是二进制的向量，那么显而易见的，存放的不是 0 ，就是 1 。 相比于传统的 List 、 Set 、 Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。

解决思路就是利用某种方法（一般是Hash 函数）把每个数据，对应到一个位图的某一位上去；如果数据存在，那一位就是1 ，不存在则为 0 。

## 4 市场营销商业指标统计分析

## 5 恶意登录监控

## 6 订单支付实时监控